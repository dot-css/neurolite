{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with NeuroLite\n",
    "\n",
    "This tutorial demonstrates how to build an image classification model using NeuroLite. We'll cover:\n",
    "\n",
    "1. Data preparation and organization\n",
    "2. Training a CNN model\n",
    "3. Model evaluation and visualization\n",
    "4. Making predictions on new images\n",
    "5. Model deployment\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "For image classification, NeuroLite expects your data to be organized in the following structure:\n",
    "\n",
    "```\n",
    "data/\n",
    "├── train/\n",
    "│   ├── class1/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "│   ├── class2/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   └── ...\n",
    "│   └── ...\n",
    "└── test/ (optional)\n",
    "    ├── class1/\n",
    "    └── class2/\n",
    "```\n",
    "\n",
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurolite\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# For this tutorial, we'll create a simple synthetic dataset\n",
    "# In practice, you would use your own image dataset\n",
    "\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create a sample dataset for demonstration\"\"\"\n",
    "    os.makedirs('sample_images/cats', exist_ok=True)\n",
    "    os.makedirs('sample_images/dogs', exist_ok=True)\n",
    "    \n",
    "    # Create synthetic images (in practice, use real images)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate \"cat\" images (more blue/gray)\n",
    "    for i in range(20):\n",
    "        img = np.random.randint(0, 100, (64, 64, 3), dtype=np.uint8)\n",
    "        img[:, :, 2] += 100  # Add blue tint\n",
    "        img = np.clip(img, 0, 255)\n",
    "        Image.fromarray(img).save(f'sample_images/cats/cat_{i}.jpg')\n",
    "    \n",
    "    # Generate \"dog\" images (more red/brown)\n",
    "    for i in range(20):\n",
    "        img = np.random.randint(0, 100, (64, 64, 3), dtype=np.uint8)\n",
    "        img[:, :, 0] += 100  # Add red tint\n",
    "        img = np.clip(img, 0, 255)\n",
    "        Image.fromarray(img).save(f'sample_images/dogs/dog_{i}.jpg')\n",
    "    \n",
    "    print(\"Sample dataset created!\")\n",
    "    print(f\"Cats: {len(os.listdir('sample_images/cats'))} images\")\n",
    "    print(f\"Dogs: {len(os.listdir('sample_images/dogs'))} images\")\n",
    "\n",
    "# Create the sample dataset\n",
    "create_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Image Classification Model\n",
    "\n",
    "Now let's train a CNN model for image classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an image classification model\n",
    "model = neurolite.train(\n",
    "    data='sample_images/',\n",
    "    model='resnet18',  # Use ResNet-18 architecture\n",
    "    task='image_classification',\n",
    "    image_size=64,  # Resize images to 64x64\n",
    "    augmentation=True,  # Apply data augmentation\n",
    "    validation_split=0.2,\n",
    "    test_split=0.1,\n",
    "    optimize=True  # Enable hyperparameter optimization\n",
    ")\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Model type: {type(model.model).__name__}\")\n",
    "print(f\"Framework: {model.framework}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Let's examine the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation metrics\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(\"========================\")\n",
    "\n",
    "metrics = model.evaluation_results.metrics\n",
    "for metric_name, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric_name.capitalize()}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric_name.capitalize()}: {value}\")\n",
    "\n",
    "# Plot training history if available\n",
    "if hasattr(model, 'training_history') and model.training_history:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'loss' in model.training_history:\n",
    "        plt.plot(model.training_history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in model.training_history:\n",
    "        plt.plot(model.training_history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'accuracy' in model.training_history:\n",
    "        plt.plot(model.training_history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in model.training_history:\n",
    "        plt.plot(model.training_history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show confusion matrix if available\n",
    "if hasattr(model.evaluation_results, 'confusion_matrix') and model.evaluation_results.confusion_matrix is not None:\n",
    "    import seaborn as sns\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        model.evaluation_results.confusion_matrix,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=['cats', 'dogs'],\n",
    "        yticklabels=['cats', 'dogs']\n",
    "    )\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Let's use our trained model to classify new images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test image for prediction\n",
    "def create_test_image(image_type='cat'):\n",
    "    \"\"\"Create a test image similar to our training data\"\"\"\n",
    "    np.random.seed(123)\n",
    "    img = np.random.randint(0, 100, (64, 64, 3), dtype=np.uint8)\n",
    "    \n",
    "    if image_type == 'cat':\n",
    "        img[:, :, 2] += 100  # Blue tint for cats\n",
    "    else:\n",
    "        img[:, :, 0] += 100  # Red tint for dogs\n",
    "    \n",
    "    img = np.clip(img, 0, 255)\n",
    "    return img\n",
    "\n",
    "# Create test images\n",
    "test_cat = create_test_image('cat')\n",
    "test_dog = create_test_image('dog')\n",
    "\n",
    "# Save test images\n",
    "Image.fromarray(test_cat).save('test_cat.jpg')\n",
    "Image.fromarray(test_dog).save('test_dog.jpg')\n",
    "\n",
    "# Display test images\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_cat)\n",
    "plt.title('Test Cat Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_dog)\n",
    "plt.title('Test Dog Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "test_images = [test_cat, test_dog]\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "class_names = ['cats', 'dogs']\n",
    "print(\"Predictions:\")\n",
    "for i, (img_type, pred) in enumerate(zip(['cat', 'dog'], predictions)):\n",
    "    predicted_class = class_names[pred] if isinstance(pred, (int, np.integer)) else pred\n",
    "    print(f\"Test {img_type} image -> Predicted: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features\n",
    "\n",
    "### Custom Image Size and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with custom parameters\n",
    "advanced_model = neurolite.train(\n",
    "    data='sample_images/',\n",
    "    model='efficientnet',  # Try a different architecture\n",
    "    task='image_classification',\n",
    "    image_size=128,  # Larger image size\n",
    "    augmentation=True,\n",
    "    augmentation_params={\n",
    "        'rotation_range': 20,\n",
    "        'width_shift_range': 0.1,\n",
    "        'height_shift_range': 0.1,\n",
    "        'horizontal_flip': True\n",
    "    },\n",
    "    validation_split=0.2,\n",
    "    optimize=False  # Skip optimization for faster training\n",
    ")\n",
    "\n",
    "print(\"Advanced model training completed!\")\n",
    "print(f\"Accuracy: {advanced_model.evaluation_results.metrics.get('accuracy', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models\n",
    "models_to_compare = ['resnet18', 'resnet50', 'efficientnet']\n",
    "results = {}\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    try:\n",
    "        trained_model = neurolite.train(\n",
    "            data='sample_images/',\n",
    "            model=model_name,\n",
    "            task='image_classification',\n",
    "            image_size=64,\n",
    "            validation_split=0.2,\n",
    "            optimize=False  # Skip optimization for speed\n",
    "        )\n",
    "        \n",
    "        accuracy = trained_model.evaluation_results.metrics.get('accuracy', 0.0)\n",
    "        results[model_name] = accuracy\n",
    "        print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to train {model_name}: {e}\")\n",
    "        results[model_name] = 0.0\n",
    "\n",
    "# Plot comparison\n",
    "if results:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    models = list(results.keys())\n",
    "    accuracies = list(results.values())\n",
    "    \n",
    "    plt.bar(models, accuracies)\n",
    "    plt.title('Model Comparison - Accuracy')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(accuracies):\n",
    "        plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Deploy your trained model for production use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "print(\"Deploying model...\")\n",
    "\n",
    "# Export to ONNX (cross-platform inference)\n",
    "try:\n",
    "    onnx_model = neurolite.deploy(model, format='onnx')\n",
    "    print(\"✓ Model exported to ONNX format\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ONNX export failed: {e}\")\n",
    "\n",
    "# Export to TensorFlow Lite (mobile deployment)\n",
    "try:\n",
    "    tflite_model = neurolite.deploy(model, format='tflite')\n",
    "    print(\"✓ Model exported to TensorFlow Lite format\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ TFLite export failed: {e}\")\n",
    "\n",
    "# Create REST API (for demonstration, we won't actually start the server)\n",
    "print(\"\\nTo deploy as REST API:\")\n",
    "print(\"api_server = neurolite.deploy(model, format='api', port=8080)\")\n",
    "print(\"# This would start a server at http://localhost:8080\")\n",
    "print(\"# POST /predict with image data to get predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Image Classification\n",
    "\n",
    "### 1. Data Quality\n",
    "- Ensure images are properly labeled\n",
    "- Use consistent image quality and resolution\n",
    "- Balance your dataset across classes\n",
    "- Remove corrupted or mislabeled images\n",
    "\n",
    "### 2. Data Augmentation\n",
    "- Use augmentation to increase dataset diversity\n",
    "- Common augmentations: rotation, flipping, scaling, color jittering\n",
    "- Be careful not to over-augment (can hurt performance)\n",
    "\n",
    "### 3. Model Selection\n",
    "- Start with ResNet-18 for quick experiments\n",
    "- Use EfficientNet for better accuracy/efficiency trade-off\n",
    "- Consider Vision Transformers (ViT) for large datasets\n",
    "\n",
    "### 4. Training Tips\n",
    "- Use transfer learning (pre-trained models)\n",
    "- Monitor validation loss to avoid overfitting\n",
    "- Use early stopping and learning rate scheduling\n",
    "- Enable hyperparameter optimization for best results\n",
    "\n",
    "### 5. Evaluation\n",
    "- Look at per-class metrics, not just overall accuracy\n",
    "- Examine confusion matrix for class-specific errors\n",
    "- Test on real-world data similar to production\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try [Object Detection Tutorial](02_object_detection.ipynb) for detecting objects in images\n",
    "- Explore [Custom Vision Models](03_custom_models.ipynb) to create your own architectures\n",
    "- Learn about [Hyperparameter Optimization](../advanced/01_hyperparameter_optimization.ipynb)\n",
    "- Check out [Model Deployment](../advanced/02_deployment.ipynb) for production deployment\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "✓ Organize image data for NeuroLite\n",
    "✓ Train CNN models with minimal code\n",
    "✓ Evaluate model performance\n",
    "✓ Make predictions on new images\n",
    "✓ Compare different model architectures\n",
    "✓ Deploy models for production use\n",
    "\n",
    "NeuroLite makes computer vision accessible while maintaining the flexibility to customize when needed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}