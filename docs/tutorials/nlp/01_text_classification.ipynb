{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with NeuroLite\n",
    "\n",
    "This tutorial demonstrates how to build text classification models using NeuroLite. We'll cover:\n",
    "\n",
    "1. Data preparation for text classification\n",
    "2. Training transformer-based models\n",
    "3. Model evaluation and analysis\n",
    "4. Making predictions on new text\n",
    "5. Advanced NLP features\n",
    "\n",
    "## Dataset Format\n",
    "\n",
    "For text classification, NeuroLite expects your data in CSV format with columns for text and labels:\n",
    "\n",
    "```csv\n",
    "text,label\n",
    "\"This movie is amazing!\",positive\n",
    "\"I didn't like this film\",negative\n",
    "\"Great acting and story\",positive\n",
    "```\n",
    "\n",
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurolite\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a sample text classification dataset\n",
    "def create_sample_text_dataset():\n",
    "    \"\"\"Create a sample movie review dataset for demonstration\"\"\"\n",
    "    \n",
    "    # Sample movie reviews\n",
    "    positive_reviews = [\n",
    "        \"This movie is absolutely fantastic! Great acting and storyline.\",\n",
    "        \"I loved every minute of this film. Highly recommended!\",\n",
    "        \"Outstanding performance by the lead actor. Must watch!\",\n",
    "        \"Brilliant cinematography and excellent direction.\",\n",
    "        \"One of the best movies I've seen this year.\",\n",
    "        \"Amazing special effects and compelling characters.\",\n",
    "        \"Wonderful story that kept me engaged throughout.\",\n",
    "        \"Superb acting and beautiful soundtrack.\",\n",
    "        \"This film exceeded all my expectations.\",\n",
    "        \"Perfect blend of action and emotion.\",\n",
    "        \"Incredible movie with outstanding performances.\",\n",
    "        \"Loved the plot twists and character development.\",\n",
    "        \"Excellent movie with great visual effects.\",\n",
    "        \"This is a masterpiece of modern cinema.\",\n",
    "        \"Fantastic storytelling and amazing cast.\"\n",
    "    ]\n",
    "    \n",
    "    negative_reviews = [\n",
    "        \"This movie was terrible. Waste of time and money.\",\n",
    "        \"Poor acting and confusing plot. Very disappointing.\",\n",
    "        \"I couldn't even finish watching this boring film.\",\n",
    "        \"Worst movie I've ever seen. Completely pointless.\",\n",
    "        \"Bad direction and terrible screenplay.\",\n",
    "        \"This film lacks any coherent storyline.\",\n",
    "        \"Awful acting and poor production quality.\",\n",
    "        \"Complete waste of time. Very boring and predictable.\",\n",
    "        \"I regret watching this movie. Total disappointment.\",\n",
    "        \"Poor character development and weak plot.\",\n",
    "        \"This movie is painfully slow and uninteresting.\",\n",
    "        \"Bad script and unconvincing performances.\",\n",
    "        \"I fell asleep halfway through this boring film.\",\n",
    "        \"Terrible movie with no redeeming qualities.\",\n",
    "        \"Poorly executed and completely forgettable.\"\n",
    "    ]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = []\n",
    "    \n",
    "    for review in positive_reviews:\n",
    "        data.append({'text': review, 'label': 'positive'})\n",
    "    \n",
    "    for review in negative_reviews:\n",
    "        data.append({'text': review, 'label': 'negative'})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('movie_reviews.csv', index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create the sample dataset\n",
    "df = create_sample_text_dataset()\n",
    "\n",
    "print(\"Sample Text Classification Dataset:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nFirst few samples:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Text Classification Model\n",
    "\n",
    "Let's train a transformer-based model for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a text classification model\n",
    "model = neurolite.train(\n",
    "    data='movie_reviews.csv',\n",
    "    model='bert',  # Use BERT transformer\n",
    "    task='text_classification',\n",
    "    target='label',\n",
    "    max_length=128,  # Maximum sequence length\n",
    "    remove_stopwords=False,  # Keep stopwords for better context\n",
    "    validation_split=0.2,\n",
    "    test_split=0.1,\n",
    "    optimize=True  # Enable hyperparameter optimization\n",
    ")\n",
    "\n",
    "print(\"Text classification model training completed!\")\n",
    "print(f\"Model type: {type(model.model).__name__}\")\n",
    "print(f\"Framework: {model.framework}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Let's analyze the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation metrics\n",
    "print(\"Text Classification Model Evaluation:\")\n",
    "print(\"====================================\")\n",
    "\n",
    "metrics = model.evaluation_results.metrics\n",
    "for metric_name, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric_name.capitalize()}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric_name.capitalize()}: {value}\")\n",
    "\n",
    "# Plot training history if available\n",
    "if hasattr(model, 'training_history') and model.training_history:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    if 'loss' in model.training_history:\n",
    "        plt.plot(model.training_history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in model.training_history:\n",
    "        plt.plot(model.training_history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if 'accuracy' in model.training_history:\n",
    "        plt.plot(model.training_history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in model.training_history:\n",
    "        plt.plot(model.training_history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot F1 score if available\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'f1' in model.training_history:\n",
    "        plt.plot(model.training_history['f1'], label='Training F1')\n",
    "    if 'val_f1' in model.training_history:\n",
    "        plt.plot(model.training_history['val_f1'], label='Validation F1')\n",
    "    plt.title('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show confusion matrix\n",
    "if hasattr(model.evaluation_results, 'confusion_matrix') and model.evaluation_results.confusion_matrix is not None:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        model.evaluation_results.confusion_matrix,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=['negative', 'positive'],\n",
    "        yticklabels=['negative', 'positive']\n",
    "    )\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Show classification report if available\n",
    "if hasattr(model.evaluation_results, 'classification_report') and model.evaluation_results.classification_report:\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(\"==============================\")\n",
    "    for class_name, metrics in model.evaluation_results.classification_report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"\\n{class_name.capitalize()}:\")\n",
    "            for metric, value in metrics.items():\n",
    "                if isinstance(value, float):\n",
    "                    print(f\"  {metric}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Let's test our model on new text samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with new text samples\n",
    "test_texts = [\n",
    "    \"This movie is absolutely incredible! I loved every second of it.\",\n",
    "    \"Boring and predictable. I want my money back.\",\n",
    "    \"The acting was decent but the plot was confusing.\",\n",
    "    \"Amazing cinematography and outstanding performances by all actors.\",\n",
    "    \"I fell asleep during the movie. Very disappointing.\",\n",
    "    \"This film is a masterpiece of storytelling and visual effects.\",\n",
    "    \"The movie was okay, nothing special but not terrible either.\",\n",
    "    \"Worst film I've ever seen. Complete waste of time.\"\n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_texts)\n",
    "\n",
    "print(\"Predictions on New Text:\")\n",
    "print(\"========================\")\n",
    "\n",
    "for i, (text, prediction) in enumerate(zip(test_texts, predictions)):\n",
    "    # Truncate long text for display\n",
    "    display_text = text if len(text) <= 60 else text[:57] + \"...\"\n",
    "    print(f\"{i+1}. \\\"{display_text}\\\"\")\n",
    "    print(f\"   Predicted: {prediction}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced NLP Features\n",
    "\n",
    "### Different Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different NLP models\n",
    "nlp_models = ['bert', 'roberta', 'distilbert']\n",
    "model_results = {}\n",
    "\n",
    "for model_name in nlp_models:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    try:\n",
    "        trained_model = neurolite.train(\n",
    "            data='movie_reviews.csv',\n",
    "            model=model_name,\n",
    "            task='text_classification',\n",
    "            target='label',\n",
    "            max_length=64,  # Shorter for faster training\n",
    "            validation_split=0.2,\n",
    "            optimize=False  # Skip optimization for speed\n",
    "        )\n",
    "        \n",
    "        accuracy = trained_model.evaluation_results.metrics.get('accuracy', 0.0)\n",
    "        f1_score = trained_model.evaluation_results.metrics.get('f1', 0.0)\n",
    "        \n",
    "        model_results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1': f1_score\n",
    "        }\n",
    "        \n",
    "        print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1: {f1_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to train {model_name}: {e}\")\n",
    "        model_results[model_name] = {'accuracy': 0.0, 'f1': 0.0}\n",
    "\n",
    "# Plot model comparison\n",
    "if model_results:\n",
    "    models = list(model_results.keys())\n",
    "    accuracies = [model_results[m]['accuracy'] for m in models]\n",
    "    f1_scores = [model_results[m]['f1'] for m in models]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8)\n",
    "    plt.bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('NLP Model Comparison')\n",
    "    plt.xticks(x, models)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (acc, f1) in enumerate(zip(accuracies, f1_scores)):\n",
    "        plt.text(i - width/2, acc + 0.01, f'{acc:.3f}', ha='center', fontsize=9)\n",
    "        plt.text(i + width/2, f1 + 0.01, f'{f1:.3f}', ha='center', fontsize=9)\n",
    "    \n",
    "    # Show training time comparison (simulated)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    training_times = [100, 120, 80]  # Simulated training times\n",
    "    plt.bar(models, training_times, alpha=0.7, color='orange')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.title('Training Time Comparison')\n",
    "    \n",
    "    for i, time in enumerate(training_times):\n",
    "        plt.text(i, time + 2, f'{time}s', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with custom preprocessing options\n",
    "custom_model = neurolite.train(\n",
    "    data='movie_reviews.csv',\n",
    "    model='distilbert',  # Faster variant of BERT\n",
    "    task='text_classification',\n",
    "    target='label',\n",
    "    max_length=256,\n",
    "    remove_stopwords=True,  # Remove common words\n",
    "    validation_split=0.2,\n",
    "    # Custom preprocessing parameters\n",
    "    lowercase=True,\n",
    "    remove_punctuation=False,  # Keep punctuation for sentiment\n",
    "    min_word_length=2,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "print(\"Custom preprocessing model training completed!\")\n",
    "print(f\"Accuracy: {custom_model.evaluation_results.metrics.get('accuracy', 'N/A'):.4f}\")\n",
    "\n",
    "# Test the custom model\n",
    "test_custom = [\n",
    "    \"This movie is AMAZING!!!\",\n",
    "    \"terrible, boring, waste of time\",\n",
    "    \"Good movie, but could be better.\"\n",
    "]\n",
    "\n",
    "custom_predictions = custom_model.predict(test_custom)\n",
    "\n",
    "print(\"\\nCustom Model Predictions:\")\n",
    "for text, pred in zip(test_custom, custom_predictions):\n",
    "    print(f\"\\\"{text}\\\" -> {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Real-World Datasets\n",
    "\n",
    "Let's try with a more realistic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a subset of 20 newsgroups dataset\n",
    "try:\n",
    "    categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "    newsgroups_train = fetch_20newsgroups(\n",
    "        subset='train',\n",
    "        categories=categories,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=('headers', 'footers', 'quotes')\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    newsgroups_df = pd.DataFrame({\n",
    "        'text': newsgroups_train.data[:200],  # Use subset for demo\n",
    "        'label': [newsgroups_train.target_names[i] for i in newsgroups_train.target[:200]]\n",
    "    })\n",
    "    \n",
    "    # Clean the text data\n",
    "    newsgroups_df['text'] = newsgroups_df['text'].str.replace('\\n', ' ').str.replace('\\t', ' ')\n",
    "    newsgroups_df['text'] = newsgroups_df['text'].str[:500]  # Truncate long texts\n",
    "    \n",
    "    # Remove empty texts\n",
    "    newsgroups_df = newsgroups_df[newsgroups_df['text'].str.len() > 10]\n",
    "    \n",
    "    newsgroups_df.to_csv('newsgroups.csv', index=False)\n",
    "    \n",
    "    print(\"20 Newsgroups Dataset:\")\n",
    "    print(f\"Total samples: {len(newsgroups_df)}\")\n",
    "    print(f\"Categories: {newsgroups_df['label'].unique()}\")\n",
    "    print(f\"Label distribution:\")\n",
    "    print(newsgroups_df['label'].value_counts())\n",
    "    \n",
    "    # Train model on newsgroups data\n",
    "    newsgroups_model = neurolite.train(\n",
    "        data='newsgroups.csv',\n",
    "        model='distilbert',\n",
    "        task='text_classification',\n",
    "        target='label',\n",
    "        max_length=256,\n",
    "        validation_split=0.2,\n",
    "        optimize=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nNewsgroups model accuracy: {newsgroups_model.evaluation_results.metrics.get('accuracy', 'N/A'):.4f}\")\n",
    "    \n",
    "    # Test with sample texts\n",
    "    test_newsgroups = [\n",
    "        \"I believe in God and follow Christian teachings.\",\n",
    "        \"Computer graphics and 3D rendering are fascinating topics.\",\n",
    "        \"Medical research shows that exercise improves health.\",\n",
    "        \"I don't believe in any religious doctrine or deity.\"\n",
    "    ]\n",
    "    \n",
    "    newsgroups_predictions = newsgroups_model.predict(test_newsgroups)\n",
    "    \n",
    "    print(\"\\nNewsgroups Predictions:\")\n",
    "    for text, pred in zip(test_newsgroups, newsgroups_predictions):\n",
    "        print(f\"\\\"{text}\\\" -> {pred}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load 20 newsgroups dataset: {e}\")\n",
    "    print(\"This is normal if you don't have internet connection or sklearn datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment for NLP\n",
    "\n",
    "Deploy your text classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the text classification model\n",
    "print(\"Deploying NLP model...\")\n",
    "\n",
    "# Export to ONNX for cross-platform inference\n",
    "try:\n",
    "    onnx_model = neurolite.deploy(model, format='onnx')\n",
    "    print(\"✓ NLP model exported to ONNX format\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ONNX export failed: {e}\")\n",
    "\n",
    "# Create REST API for text classification\n",
    "print(\"\\nTo deploy as REST API for text classification:\")\n",
    "print(\"api_server = neurolite.deploy(model, format='api', port=8080)\")\n",
    "print(\"\")\n",
    "print(\"API Usage:\")\n",
    "print(\"POST /predict\")\n",
    "print(\"Content-Type: application/json\")\n",
    "print(\"Body: {\\\"text\\\": \\\"Your text to classify\\\"}\")\n",
    "print(\"\")\n",
    "print(\"Response: {\\\"prediction\\\": \\\"positive\\\", \\\"confidence\\\": 0.95}\")\n",
    "\n",
    "# Save model for later use\n",
    "try:\n",
    "    model.save('text_classification_model')\n",
    "    print(\"\\n✓ Model saved to 'text_classification_model' directory\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model save failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Text Classification\n",
    "\n",
    "### 1. Data Preparation\n",
    "- Clean your text data (remove HTML, special characters if needed)\n",
    "- Handle class imbalance with stratified sampling\n",
    "- Use appropriate train/validation/test splits\n",
    "- Consider data augmentation for small datasets\n",
    "\n",
    "### 2. Model Selection\n",
    "- **BERT**: Best overall performance, slower training\n",
    "- **DistilBERT**: Faster training, 97% of BERT performance\n",
    "- **RoBERTa**: Often better than BERT on many tasks\n",
    "- **ELECTRA**: More efficient pre-training, good performance\n",
    "\n",
    "### 3. Hyperparameter Tuning\n",
    "- **max_length**: Balance between context and efficiency\n",
    "- **learning_rate**: Start with 2e-5 for BERT-based models\n",
    "- **batch_size**: Larger is better, limited by GPU memory\n",
    "- **epochs**: Usually 3-5 epochs for fine-tuning\n",
    "\n",
    "### 4. Evaluation Metrics\n",
    "- **Accuracy**: Good for balanced datasets\n",
    "- **F1-score**: Better for imbalanced datasets\n",
    "- **Precision/Recall**: Important for specific use cases\n",
    "- **Confusion Matrix**: Understand per-class performance\n",
    "\n",
    "### 5. Common Issues and Solutions\n",
    "- **Overfitting**: Use dropout, early stopping, smaller learning rate\n",
    "- **Slow training**: Use DistilBERT, reduce max_length, increase batch_size\n",
    "- **Poor performance**: Check data quality, try different models, tune hyperparameters\n",
    "- **Memory issues**: Reduce batch_size, use gradient accumulation\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try [Sentiment Analysis Tutorial](02_sentiment_analysis.ipynb) for specialized sentiment tasks\n",
    "- Explore [Custom NLP Models](03_custom_models.ipynb) to create domain-specific models\n",
    "- Learn about [Hyperparameter Optimization](../advanced/01_hyperparameter_optimization.ipynb)\n",
    "- Check out [Model Deployment](../advanced/02_deployment.ipynb) for production deployment\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "✓ Prepare text data for classification\n",
    "✓ Train transformer-based models with NeuroLite\n",
    "✓ Evaluate model performance with appropriate metrics\n",
    "✓ Make predictions on new text\n",
    "✓ Compare different NLP model architectures\n",
    "✓ Apply custom preprocessing options\n",
    "✓ Work with real-world datasets\n",
    "✓ Deploy models for production use\n",
    "\n",
    "NeuroLite makes NLP accessible while providing the flexibility to customize for your specific needs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}